{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Models for Twitter Sentiment Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will test the effectiveness of non-deep learning models. We will work with Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shivaomrani/opt/anaconda3/envs/neural_networks/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/shivaomrani/opt/anaconda3/envs/neural_networks/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/shivaomrani/opt/anaconda3/envs/neural_networks/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/shivaomrani/opt/anaconda3/envs/neural_networks/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/shivaomrani/opt/anaconda3/envs/neural_networks/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/shivaomrani/opt/anaconda3/envs/neural_networks/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/shivaomrani/opt/anaconda3/envs/neural_networks/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/shivaomrani/opt/anaconda3/envs/neural_networks/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/shivaomrani/opt/anaconda3/envs/neural_networks/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/shivaomrani/opt/anaconda3/envs/neural_networks/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/shivaomrani/opt/anaconda3/envs/neural_networks/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/shivaomrani/opt/anaconda3/envs/neural_networks/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob, os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper methods for reading tweets and cleaning them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tsv(file_path):\n",
    "    df = pd.read_table(file_path)\n",
    "    return df\n",
    "\n",
    "import string\n",
    "import re\n",
    "\n",
    "# code inspired from https://www.kaggle.com/rahulvv/bidirectional-lstm-glove200d\n",
    "\n",
    "\n",
    "def remove_urls(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'',text)\n",
    "  \n",
    "def remove_html(text):\n",
    "    html=re.compile(r'<.*?>')\n",
    "    return html.sub(r'',text)\n",
    "\n",
    "def split_text(text):\n",
    "    text = text.split()\n",
    "    return text\n",
    "\n",
    "def lower(text):\n",
    "    text = [word.lower() for word in text]\n",
    "    return str(text)\n",
    "\n",
    "def remove_punct(text):\n",
    "    text = ''.join([char for char in text if char not in string.punctuation])\n",
    "    text = re.sub('[0-9]+', '', str(text))\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    pattern = re.compile(r'\\b('+r'|'.join(stopwords.words('english')) + r')\\b\\s*')\n",
    "    text = pattern.sub(' ', text)\n",
    "    return text\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_words(text):\n",
    "    text = lemmatizer.lemmatize(text)\n",
    "    return text\n",
    "\n",
    "def clean_tweet(text):\n",
    "    t0 = remove_urls(text)\n",
    "    t1 = remove_html(t0)\n",
    "    t2 = split_text(t1)\n",
    "    t3 = lower(t2)\n",
    "    t4 = remove_punct(t3)\n",
    "    t5 = remove_stopwords(t4)\n",
    "    t6 = lemmatize_words(t5)\n",
    "    return t6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = pd.DataFrame(columns=['tweet', 'sentiment','NA'])\n",
    "df_test = pd.DataFrame(columns=['tweet', 'sentiment','NA'])\n",
    "\n",
    "for file in glob.glob(\"*.tsv\"):\n",
    "        if 'final_test' in file:\n",
    "            df_test_cur = read_tsv(file)\n",
    "            df_test = pd.concat([df_test, df_test_cur])\n",
    "        else:\n",
    "            df_train_cur = read_tsv(file)\n",
    "            tweet_df = pd.concat([tweet_df, df_train_cur])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  tweet sentiment\n",
      "0     05 Beat it - Michael Jackson - Thriller (25th ...   neutral\n",
      "1     Jay Z joins Instagram with nostalgic tribute t...  positive\n",
      "2     Michael Jackson: Bad 25th Anniversary Edition ...   neutral\n",
      "3     I liked a @YouTube video http://t.co/AaR3pjp2P...  positive\n",
      "4     18th anniv of Princess Diana's death. I still ...  positive\n",
      "...                                                 ...       ...\n",
      "1137                     Maybe it was - his - fantasy ?  positive\n",
      "1138  It was ok , but they always just seem so nervo...  negative\n",
      "1139  It is streamable from YepRoc -- matter of fact...  positive\n",
      "1140  comment telling me who you are , or how you fo...  positive\n",
      "1141  im on myspace ... ill try and find you and add...   neutral\n",
      "\n",
      "[53368 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(tweet_df[['tweet', 'sentiment']] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   tweet sentiment\n",
      "0      #ArianaGrande Ari By Ariana Grande 80% Full ht...   neutral\n",
      "1      Ariana Grande KIIS FM Yours Truly CD listening...  positive\n",
      "2      Ariana Grande White House Easter Egg Roll in W...  positive\n",
      "3      #CD #Musics Ariana Grande Sweet Like Candy 3.4...  positive\n",
      "4      SIDE TO SIDE üòò @arianagrande #sidetoside #aria...   neutral\n",
      "...                                                  ...       ...\n",
      "11901  @dansen17 update: Zac Efron kissing a puppy ht...  positive\n",
      "11902  #zac efron sex pic skins michelle sex https://...   neutral\n",
      "11903  First Look at Neighbors 2 with Zac Efron Shirt...   neutral\n",
      "11904  zac efron poses nude #lovely libra porn https:...   neutral\n",
      "11905  #Fashion #Style The Paperboy (NEW Blu-ray Disc...   neutral\n",
      "\n",
      "[11906 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_test[['tweet', 'sentiment']] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading Glove word embeddings into a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing train lables\n",
    "tweet_df.loc[tweet_df.sentiment == \"positive\", \"sentiment\"] = 2\n",
    "tweet_df.loc[tweet_df.sentiment == \"neutral\", \"sentiment\"] = 1\n",
    "tweet_df.loc[tweet_df.sentiment == \"negative\", \"sentiment\"] = 0\n",
    "\n",
    "labels = tweet_df[\"sentiment\"].tolist()\n",
    "labels = [ int(x) for x in labels ]\n",
    "\n",
    "#preparing test labels\n",
    "df_test.loc[df_test.sentiment == \"positive\", \"sentiment\"] = 2\n",
    "df_test.loc[df_test.sentiment == \"neutral\", \"sentiment\"] = 1\n",
    "df_test.loc[df_test.sentiment == \"negative\", \"sentiment\"] = 0\n",
    "\n",
    "labels_test = df_test[\"sentiment\"].tolist()\n",
    "labels_test = [ int(x) for x in labels_test ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting tweets and labels into lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tweets = tweet_df.tweet.values\n",
    "y_train_orig = tweet_df.sentiment.values\n",
    "test_tweets = df_test.tweet.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(y_train_orig)\n",
    "\n",
    "clean_training_tweets = []\n",
    "for i in range(len(train_tweets)):\n",
    "    data = clean_tweet(train_tweets[i])\n",
    "    clean_training_tweets.append(data)\n",
    "\n",
    "clean_testing_tweets = []\n",
    "for i in range(len(test_tweets)):\n",
    "    data = clean_tweet(test_tweets[i])\n",
    "    clean_testing_tweets.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the tweets after cleaning them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' beat  michael jackson  thriller th anniversary edition hd', 'jay z joins instagram  nostalgic tribute  michael jackson jay z apparently joined instagram  saturday  ', 'michael jackson bad th anniversary edition picture vinyl  unique picture disc vinyl includes  original ', ' liked  youtube video one direction singing man   mirror  michael jackson  atlanta ga june ', 'th anniv  princess dianas death  still want  believe   living   private island away   public  michael jackson', 'oridaganjazz  st time  heard michael jackson sing   honolulu hawaii   restaurant  radio   abc    loved  ', 'michael jackson appeared  saturday    th place   top  miamis trends trndnl', '  old enough  remember michael jackson attending  grammys  brooke shields  webster sat   lap   show', 'etbowser  u enjoy  nd rate michael jackson bit honest ques like  cant feel face song  god   obvious  want mj ', ' weeknd   closest thing  may get  michael jackson   long timeespecially since  damn near mimics everything']\n",
      "['arianagrande ari  ariana grande  full singer actress', 'ariana grande kiis fm  truly cd listening party  burbank arianagrande', 'ariana grande white house easter egg roll  washington arianagrande', 'cd musics ariana grande sweet like candy  oz  ml sealed  box  authenic new', 'side  side üòò arianagrande sidetoside arianagrande musically comunidadgay lgbtüåà lotb‚Ä¶', 'hairspray live previews   macys thanksgiving day parade arianagrande televisionnbc', 'lindsaylohan  ‚Äòfeeling thankful‚Äô  blasting arianagrande  wearing ‚Äòtoomuch‚Ä¶', ' hate    love  songs dammit arianagrande', 'ariana grande „Äêright  ft big sean„Äë„Ç¢„É™„Ç¢„Éä arianagrande', ' one would  prefer  listen    whole day üòçü§òüèº  could never choose arianagrande intoyou sidetoside songs poll']\n"
     ]
    }
   ],
   "source": [
    "print(clean_training_tweets[:10])\n",
    "print(clean_testing_tweets[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import ConditionalFreqDist\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets = clean_training_tweets + clean_testing_tweets\n",
    "\n",
    "length = len(clean_training_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(binary=True, ngram_range = (1,3))\n",
    "bow= cv.fit_transform(all_tweets)\n",
    "bow_train = bow[:length]\n",
    "bow_test = bow[length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Naive Bayes\n",
      "[[2831  692  288]\n",
      " [2412 2217 1114]\n",
      " [ 404  515 1433]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.74      0.60      3811\n",
      "           1       0.65      0.39      0.48      5743\n",
      "           2       0.51      0.61      0.55      2352\n",
      "\n",
      "    accuracy                           0.54     11906\n",
      "   macro avg       0.55      0.58      0.54     11906\n",
      "weighted avg       0.57      0.54      0.53     11906\n",
      "\n",
      "0.5443473878716614\n"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB(alpha= 1.0).fit(bow_train, labels)\n",
    "label_pred = model.predict(bow_test)\n",
    "\n",
    "print(\"Classification Report for Naive Bayes\")\n",
    "print(confusion_matrix(labels_test,label_pred))\n",
    "print(classification_report(labels_test,label_pred))\n",
    "print(accuracy_score(labels_test, label_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:neural_networks] *",
   "language": "python",
   "name": "conda-env-neural_networks-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
